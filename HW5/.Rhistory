tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Blues"))
title(paste(paste(paste("Top",nt),"words on\nTwitter about"),topic))
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(enc2utf8(x), sub = "byte")) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
VectorSource(base_tweets$.)
VectorSource(base_tweets$.) %>%
Corpus()
VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(enc2utf8(x), sub = "byte"))
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte'))
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
tweets
wordcloud(tweets, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Blues"))
title(paste(paste(paste("Top",nt),"words on\nTwitter about"),topic))
top.tweets <- str_split(tweets, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:nt] %>%
data.frame()
top.tweets <- cbind(rownames(top.tweets), top.tweets)
rownames(top.tweets) <- NULL
colnames(top.tweets) <- c("Word","Counts")
datatable(top.tweets)
base_tweets <- searchTwitter(topic, lang="en", since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Blues"))
title(paste(paste(paste("Top",nt),"words on\nTwitter about"),topic))
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste("Top",nt),"words on\nTwitter about"),topic))
top.tweets <- str_split(tweets, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:nt] %>%
data.frame()
# Name columns
top.tweets <- cbind(rownames(top.tweets), top.tweets)
rownames(top.tweets) <- NULL
colnames(top.tweets) <- c("Word","Counts")
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n"),start.date), "to",end.date))
)
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n"),start.date), "to"),end.date))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
topic <- "ronaldo"
base_tweets <- searchTwitter(topic, lang="en", since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
length(base_tweets)
nrow(base_tweets)
start.date <- "2013-01-01"
start.date <- "2013-01-01"
end.date <- "2015-04-30"
base_tweets <- searchTwitter(topic, lang="en", since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
nrow(base_tweets)
base_tweets <- searchTwitter(topic, lang="en",n=1000, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
nrow(base_tweets)
base_tweets <- searchTwitter(topic, lang="en",n=nt, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
nrow(base_tweets)
# Clean it up.
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
top.tweets <- str_split(tweets, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame()
# Name columns
top.tweets <- cbind(rownames(top.tweets), top.tweets)
rownames(top.tweets) <- NULL
colnames(top.tweets) <- c("Word","Counts")
# Make data table.
datatable(top.tweets)
nrow(base_tweets)
nt <- 1000      # n for number of tweets.
base_tweets <- searchTwitter(topic, lang="en",n=nt, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
nrow(base_tweets)
nrow(base_tweets)
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, scale=c(10,1), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, scale=c(5,1), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(tweets, scale=c(5,2), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(tweets, scale=c(10,2), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, scale=c(20,2), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, scale=c(5,2), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
topic <- "data"
base_tweets <- searchTwitter(topic, lang="en",n=nt, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
nrow(base_tweets)
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, scale=c(5,0.5), max.words=100, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
wordcloud(tweets, max.words=100,scale=c(5,0.5), size = 3, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(tweets, max.words=100,scale=c(5,0.5), size = 1, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
wordcloud(tweets, max.words=100,scale=c(5,0.5), size = 10, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
warnings()
topic <- "data science"     # 'topic' defines what is searched in Twitter.
base_tweets <- searchTwitter(topic, lang="en",n=nt, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, max.words=100,scale=c(5,0.5), random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
title(paste(paste(paste(paste(paste("Tweets about", topic),"from\n "),start.date), "to"),end.date))
start.date <- "2015-01-01"  # Start date of Twitter search.
base_tweets <- searchTwitter(topic, lang="en",n=nt, since=start.date, until=end.date) %>%
sapply(function(x) x$getText()) %>%
data.frame()
tweets <- VectorSource(base_tweets$.) %>%
Corpus() %>%
tm_map( function(x) iconv(x, to='UTF-8-MAC', sub='byte')) %>%
tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
wordcloud(tweets, max.words=100,scale=c(5,0.5), random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Dark2"))
suppressWarnings(library(ggplot2))
library(tidyr)
library(dplyr)
trial <- rep(c(1,2,3),times = c(24,54,11))
Dia <- rep(c(D1,D2,D3), times = c(24,54,11))
height <- rep(c(1.27,1.51,1.26,1.01,1.26), times = c(24,17,19,18,11))
bar <- rep(c(2.75,3.0,3.25,2.75,3.0,3.25,3.0), times = c(0,24,0,17,19,18,11))
collision <- c(seq(1,24),seq(1,17),seq(1,19),seq(1,18),seq(1,11))
gamma <- rep(c(264,268,264,252,256), times = c(24,17,19,18,11))
gammaF <- rep(c(270,270,268,256,262), times = c(24,17,19,18,11))
v_perp <- c(1.67,5.90,6.07,6.66,6.21,6.99,8.49,8.53,7.49,7.45,4.10,4.51,6.72,7.24,7.31,7.11,7.72,5.07,5.19,4.30,4.81,5.23,6.22,6.64,9.05,8.60,9.59,9.38,10.33,8.70,9.60,8.69,10.25,9.98,9.72,9.91,9.00,9.99,9.95,10.27,10.38,5.02,5.89,9.20,6.48,8.23,10.40,10.76,9.62,7.21,8.03,9.25,8.44,9.75,10.77,4.95,8.18,10.05,11.67,3.91,9.41,9.59,10.30,8.85,7.43,9.75,6.26,8.61,10.81,9.57,9.55,9.73,10.92,6.70,5.18,9.23,3.82,8.02,7.57,5.78,7.32,9.62,7.95,7.35,4.38,8.58,8.08,6.94,9.86)
tun <- c("R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","R","R","R","T","R","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","R","R","R","T","T","R","T","T","R","T","T","R","R","R","R","R","R","T","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","T","R","T","R","R","T")
verr <- rep(0.2,times = (24+54+11))
vdf <- data.frame(trial,collision, Dia, bar, height, v_perp, verr, tun, gamma, gammaF)
vdf <- mutate(vdf, "Memory" = gamma/gammaF)
D1 <- round(mean(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672)), digits = 2)
D_SE1 <- round(sd(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672))/sqrt(9), digits = 2)
D2 <- round(mean(c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078)), digits = 2)
D_SE2 <- round(sd(c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078))/sqrt(9), digits = 2)
D3 <- round(mean(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)), digits = 2)
D_SE3 <- round(sd(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))/sqrt(9), digits = 2)
D <- c(D1,D1,D1,D2,D2,D2,D3)
trial <- rep(c(1,2,3),times = c(24,54,11))
Dia <- rep(c(D1,D2,D3), times = c(24,54,11))
height <- rep(c(1.27,1.51,1.26,1.01,1.26), times = c(24,17,19,18,11))
bar <- rep(c(2.75,3.0,3.25,2.75,3.0,3.25,3.0), times = c(0,24,0,17,19,18,11))
collision <- c(seq(1,24),seq(1,17),seq(1,19),seq(1,18),seq(1,11))
gamma <- rep(c(264,268,264,252,256), times = c(24,17,19,18,11))
gammaF <- rep(c(270,270,268,256,262), times = c(24,17,19,18,11))
v_perp <- c(1.67,5.90,6.07,6.66,6.21,6.99,8.49,8.53,7.49,7.45,4.10,4.51,6.72,7.24,7.31,7.11,7.72,5.07,5.19,4.30,4.81,5.23,6.22,6.64,9.05,8.60,9.59,9.38,10.33,8.70,9.60,8.69,10.25,9.98,9.72,9.91,9.00,9.99,9.95,10.27,10.38,5.02,5.89,9.20,6.48,8.23,10.40,10.76,9.62,7.21,8.03,9.25,8.44,9.75,10.77,4.95,8.18,10.05,11.67,3.91,9.41,9.59,10.30,8.85,7.43,9.75,6.26,8.61,10.81,9.57,9.55,9.73,10.92,6.70,5.18,9.23,3.82,8.02,7.57,5.78,7.32,9.62,7.95,7.35,4.38,8.58,8.08,6.94,9.86)
tun <- c("R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","R","R","R","T","R","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","R","R","R","T","T","R","T","T","R","T","T","R","R","R","R","R","R","T","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","T","R","T","R","R","T")
verr <- rep(0.2,times = (24+54+11))
vdf <- data.frame(trial,collision, Dia, bar, height, v_perp, verr, tun, gamma, gammaF)
vdf <- mutate(vdf, "Memory" = gamma/gammaF)
ggplot(df, aes(height, , col = factor(D), shape = factor(D))) +
geom_point(size = 3) +
geom_errorbarh(aes(xmin=h-h_E, xmax=h+h_E), height=.03) +
xlab("Oil Height (mm)") +
ylab("Probability of Tunneling") +
#ggtitle("Tunneling Probability by\n Height of Oil Above Barrier") +
guides(colour = guide_legend("Droplet\nDiameter (mm)"), shape = guide_legend("Droplet\nDiameter (mm)"))
vdf <- mutate(vdf, jitterD = jitter(Dia))
vdf <- mutate(vdf, jittert = jitter(trial))
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
verr <- rep(0.01,times = (24+54+11))
vdf <- data.frame(trial,collision, Dia, bar, height, v_perp, verr, tun, gamma, gammaF)
vdf <- mutate(vdf, "Memory" = gamma/gammaF)
vdf <- mutate(vdf, jitterD = jitter(Dia))
vdf <- mutate(vdf, jittert = jitter(trial))
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
#geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
View(vdf)
install.packages("xtable")
library(xtable)
print(vdf)
h <- c(1.52,1.27,1.02,1.51,1.26,1.01,1.26)
h_E <- c(0.04, 0.035, 0.034, 0.034, 0.034,0.034,0.034)
T <- c(1.0, 2/24, 0.0, 17/17, 7/19, 0/18, 4/13)
barrier <- c(2.75,3.0,3.25,2.75,3.0,3.25,3.0)
trial <- c(1,1,1,2,2,2,3)
D1 <- round(mean(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672)), digits = 2)
D_SE1 <- round(sd(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672))/sqrt(9), digits = 2)
D2 <- round(mean(c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078)), digits = 2)
D_SE2 <- round(sd(c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078))/sqrt(9), digits = 2)
D3 <- round(mean(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)), digits = 2)
D_SE3 <- round(sd(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))/sqrt(9), digits = 2)
D <- c(D1,D1,D1,D2,D2,D2,D3)
sd(rep(c(1,0), times = c(2,22)))/sqrt(24)
SE <- c(0,sd(rep(c(1,0), times = c(2,22)))/sqrt(24), 0, 0, sd(rep(c(1,0), times = c(7,12)))/sqrt(19),0, sd(rep(c(1,0), times = c(4,9)))/sqrt(13))
length(SE)
df <- data.frame(trial, barrier, h, h_E, T, D, SE)
print(df)
H <- rep(4.26, times = 7)
H
df <- data.frame(trial, barrier, h, h_E, H, T, D, SE)
print(df)
gamma <- c(284,264,252,268,264,252,256)
gammaF <- c(290,270,258,270,268,256,262)
df <- data.frame(trial, barrier, gamma, gammaF,T, D, h, h_E, H)
print(df)
D_SE <- c(D_SE1,D_SE1,D_SE1,D_SE2,D_SE2,D_SE2,D_SE3,D_SE3,D_SE3)
df <- data.frame(trial, barrier, gamma, gammaF,T, D,D_SE, h, h_E, H)
print(df)
D_SE <- c(D_SE1,D_SE1,D_SE1,D_SE2,D_SE2,D_SE2,D_SE3)
df <- data.frame(trial, barrier, gamma, gammaF,T, D,D_SE, h, h_E, H)
print(df)
DD1 <- c(c(0.9876,1.011,1.048),c(0.9968,0.9789,0.9676),c(0.9969,0.9969,0.9672))
DD3 <- c(c(1.089,0.9754,1.058),c(1.001,0.9794,1.030),c(0.9193,0.9878,1.090))
DD2 <- c(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,?))
DD1 <- c(c(0.9876,1.011,1.048),c(0.9968,0.9789,0.9676),c(0.9969,0.9969,0.9672))
DD3 <- c(c(1.089,0.9754,1.058),c(1.001,0.9794,1.030),c(0.9193,0.9878,1.090))
DD <- c(DD1,DD2,DD3)
DD2 <- c(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,?))
DD <- c(DD1,DD2,DD3)
DD2 <- c(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,"?"))
DD <- c(DD1,DD2,DD3)
DD
DD2 <- c({c(1.042,1.094,1.113)},{c(1.011,1.154, 1.030)},{c(1.054,1.078,"?")})
DD2
DD2 <- c((1.042,1.094,1.113),(1.011,1.154, 1.030),(1.054,1.078,"?"))
DD2
DD2 <- c({1.042,1.094,1.113},{1.011,1.154, 1.030},{1.054,1.078,"?"})
DD2 <- c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078,"?")
split(DD2,3)
split(DD2,3)
DD2 <- c(1.042,1.094,1.113,1.011,1.154, 1.030,1.054,1.078,1.062)
D2 <- round(mean(c(1.042,1.094,1.113,1.011,1.154,1.030,1.054,1.078,1.062)), digits = 2)
D_SE2 <- round(sd(c(1.042,1.094,1.113,1.011,1.154,1.030,1.054,1.078,1.062))/sqrt(9), digits = 2)
trial <- rep(c(1,2,3),times = c(24,54,11))
Dia <- rep(c(D1,D2,D3), times = c(24,54,11))
height <- rep(c(1.27,1.51,1.26,1.01,1.26), times = c(24,17,19,18,11))
bar <- rep(c(2.75,3.0,3.25,2.75,3.0,3.25,3.0), times = c(0,24,0,17,19,18,11))
collision <- c(seq(1,24),seq(1,17),seq(1,19),seq(1,18),seq(1,11))
gamma <- rep(c(264,268,264,252,256), times = c(24,17,19,18,11))
gammaF <- rep(c(270,270,268,256,262), times = c(24,17,19,18,11))
v_perp <- c(1.67,5.90,6.07,6.66,6.21,6.99,8.49,8.53,7.49,7.45,4.10,4.51,6.72,7.24,7.31,7.11,7.72,5.07,5.19,4.30,4.81,5.23,6.22,6.64,9.05,8.60,9.59,9.38,10.33,8.70,9.60,8.69,10.25,9.98,9.72,9.91,9.00,9.99,9.95,10.27,10.38,5.02,5.89,9.20,6.48,8.23,10.40,10.76,9.62,7.21,8.03,9.25,8.44,9.75,10.77,4.95,8.18,10.05,11.67,3.91,9.41,9.59,10.30,8.85,7.43,9.75,6.26,8.61,10.81,9.57,9.55,9.73,10.92,6.70,5.18,9.23,3.82,8.02,7.57,5.78,7.32,9.62,7.95,7.35,4.38,8.58,8.08,6.94,9.86)
tun <- c("R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","R","R","R","T","R","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","T","R","R","R","T","T","R","T","T","R","T","T","R","R","R","R","R","R","T","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","R","T","R","T","R","T","R","R","T")
verr <- rep(0.01,times = (24+54+11))
vdf <- data.frame(trial,collision, Dia, bar, height, v_perp, verr, tun, gamma, gammaF)
vdf <- mutate(vdf, "Memory" = gamma/gammaF)
memory_SE <- sd(unique((vdf$gamma)/vdf$gammaF))/sqrt(length(unique((vdf$gamma)/vdf$gammaF)))
memory_AVG <- mean(unique(vdf$Memory))
a <- vdf$gamma[2]
b <- vdf$gammaF[2]
mem_unc <- sqrt( (5)^2/b^2  + a^2*5^2/b^4 )
ggplot(vdf, aes(x = height, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Oil Height (mm)") +
ylab("Perpendicular Velocity (mm/s)") +
ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)"))
ggplot(df, aes(height, , col = factor(D), shape = factor(D))) +
geom_point(size = 3) +
geom_errorbarh(aes(xmin=h-h_E, xmax=h+h_E), height=.03) +
xlab("Oil Height (mm)") +
ylab("Probability of Tunneling") +
#ggtitle("Tunneling Probability by\n Height of Oil Above Barrier") +
guides(colour = guide_legend("Droplet\nDiameter (mm)"), shape = guide_legend("Droplet\nDiameter (mm)"))
ggplot(vdf, aes(x = jittert, v_perp, col = tun)) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
#geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
)
ggplot(vdf, aes(x = jittert, v_perp, col = tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
#geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
)
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia)))
vdf <- mutate(vdf, jitterD = jitter(Dia))
vdf <- mutate(vdf, jittert = jitter(trial))
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5)) +
#geom_errorbar(aes(ymin=v_perp-verr, ymax=v_perp+verr), width=0.03)
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
#ggtitle("Is Tunneling Dependent on\nPerpendicular Velocity?") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5))
ggplot(vdf, aes(x = jittert, v_perp, col = factor(tun))) +
geom_point(size = 3, aes(shape = factor(Dia))) +
xlab("Trial") +
ylab("Perpendicular Velocity (mm/s)") +
guides(colour = guide_legend("Tunneling"), shape = guide_legend("Droplet\nDiameter (mm)")) +
scale_x_discrete(limits = c(1,2,3),labels=c("1","2","3")) +
coord_cartesian(xlim = c(0.5,3.5))
DD3 <- c(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))
DD1 <- list(list(0.9876,1.011,1.048),list(0.9968,0.9789,0.9676),list(0.9969,0.9969,0.9672))
DD2 <- list(list(1.042,1.094,1.113),list(1.011,1.154, 1.030),list(1.054,1.078,1.062))
DD3 <- list(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)
DD1
DD <- c(DD1,DD2,DD3)
DD
df <- data.frame(trial, barrier, gamma, gammaF,T, DD, h, h_E, H)
DD1 <- list(c(0.9876,1.011,1.048),c(0.9968,0.9789,0.9676),c(0.9969,0.9969,0.9672))
DD2 <- list(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,1.062))
DD3 <- list(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)
DD <- c(DD1,DD2,DD3)
DD
DD3 <- c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)
DD <- c(DD1,DD2,DD3)
D
DD
DD3 <- list(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))
DD <- c(DD1,DD2,DD3)
DD
df <- data.frame(trial, barrier, gamma, gammaF,T, DD, h, h_E, H)
h <- c(1.52,1.27,1.02,1.51,1.26,1.01,1.26)
h_E <- c(0.04, 0.035, 0.034, 0.034, 0.034,0.034,0.034)
T <- c(1.0, 2/24, 0.0, 17/17, 7/19, 0/18, 4/13)
barrier <- c(2.75,3.0,3.25,2.75,3.0,3.25,3.0)
trial <- c(1,1,1,2,2,2,3)
H <- rep(4.26, times = 7)
gamma <- c(284,264,252,268,264,252,256)
gammaF <- c(290,270,258,270,268,256,262)
DD1 <- list(c(0.9876,1.011,1.048),c(0.9968,0.9789,0.9676),c(0.9969,0.9969,0.9672))
D1 <- round(mean(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672)), digits = 2)
D_SE1 <- round(sd(c(0.9876,1.011,1.048,0.9968,0.9789,0.9676,0.9969,0.9969,0.9672))/sqrt(9), digits = 2)
DD2 <- list(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,1.062))
D2 <- round(mean(c(1.042,1.094,1.113,1.011,1.154,1.030,1.054,1.078,1.062)), digits = 2)
D_SE2 <- round(sd(c(1.042,1.094,1.113,1.011,1.154,1.030,1.054,1.078,1.062))/sqrt(9), digits = 2)
DD3 <- list(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))
D3 <- round(mean(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090)), digits = 2)
D_SE3 <- round(sd(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))/sqrt(9), digits = 2)
split(DD2,3)
DD <- c(DD1,DD2,DD3)
D <- c(D1,D1,D1,D2,D2,D2,D3)
df <- data.frame(trial, barrier, gamma, gammaF,T, DD, h, h_E, H)
DD
DD1 <- c(list(0.9876,1.011,1.048),list(0.9968,0.9789,0.9676),list(0.9969,0.9969,0.9672))
DD2 <- c(list(1.042,1.094,1.113),list(1.011,1.154, 1.030),list(1.054,1.078,1.062))
DD3 <- c(list(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))
DD <- c(DD1,DD2,DD3)
DD
DD1 <- list(c(0.9876,1.011,1.048),c(0.9968,0.9789,0.9676),c(0.9969,0.9969,0.9672))
DD2 <- list(c(1.042,1.094,1.113),c(1.011,1.154, 1.030),c(1.054,1.078,1.062))
DD3 <- list(c(1.089,0.9754,1.058,1.001,0.9794,1.030,0.9193,0.9878,1.090))
DD <- c(DD1,DD2,DD3)
DD
df
print.xtable(df)
df$trial[1]
is.numeric(df$trial[1])
is.numeric(df$barrier[1])
is.numeric(df$gamma[1])
df <- data.frame(trial, barrier, gamma, gammaF,T, D, h, h_E, H)
print.xtable(df)
df
is.numeric(df$gammaF[1])
is.numeric(df$T[1])
is.numeric(df$D[1])
is.numeric(df$h[1])
is.numeric(df$h_E[1])
is.numeric(df$H[1])
is.numeric(df)
print(df)
print.xtable(df)
print(xtable(df))
