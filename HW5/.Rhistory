)
# A certain number of the geocoordinates are missing.
# Remove these.  We have to be careful about the bias this may entail.  A more
# thorough analysis would see if there is a pattern in which data are missing.
suppressWarnings(
crime_data <- crime_data %>%
mutate(
X.Coordinate = as.numeric(as.character(X.Coordinate)),
Y.Coordinate = as.numeric(as.character(Y.Coordinate))
) %>%
filter(!is.na(X.Coordinate) & !is.na(Y.Coordinate)) %>%
filter(X.Coordinate != "" & Y.Coordinate != "")
)
lat.long <-
select(crime_data, X.Coordinate, Y.Coordinate) %>%
NAD.to.latlong()
crime_data <- bind_cols(crime_data, lat.long)
setwd("~/Desktop/Math  241 (Case Studies - Statistical Analysis)/Math-241-Assignments/HW4")
# Import data. CSV files from all years have been merged into one file using Terminal.
crime_data <- read.csv("crime_data.csv", header = TRUE) %>% tbl_df()
# Clean up date data.
suppressWarnings(
crime_data <- crime_data %>% mutate(date = mdy(date))
)
# A certain number of the geocoordinates are missing.
# Remove these.  We have to be careful about the bias this may entail.  A more
# thorough analysis would see if there is a pattern in which data are missing.
suppressWarnings(
crime_data <- crime_data %>%
mutate(
X.Coordinate = as.numeric(as.character(X.Coordinate)),
Y.Coordinate = as.numeric(as.character(Y.Coordinate))
) %>%
filter(!is.na(X.Coordinate) & !is.na(Y.Coordinate)) %>%
filter(X.Coordinate != "" & Y.Coordinate != "")
)
lat.long <-
select(crime_data, X.Coordinate, Y.Coordinate) %>%
NAD.to.latlong()
crime_data <- bind_cols(crime_data, lat.long)
crime_data$group <- 76
crime <- as.character(input$crime)
crime_data <- crime_data %>%
mutate(crimeyear = as.numeric(year(date)))
dt <- crime_data %>%
group_by(crimeyear, offense) %>%
subset(offense == crime)
year <- c(2014)
crime <- "Rape"
dt <- crime_data %>%
group_by(crimeyear, offense) %>%
subset(offense == crime)
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear == year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,crimeyear != year),binwidth=1,fill="darkgrey4") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste("Number of",crime)) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear == year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,crimeyear != year),binwidth=1,fill="darkgrey") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste("Number of",crime)) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear == year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,crimeyear != year),binwidth=1,fill="gray25") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste("Number of",crime)) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
year <- c(2013,2014)
crime <- "Rape"
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear == year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,crimeyear != year),binwidth=1,fill="gray25") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste("Number of",crime)) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
(crimeyear, allequal(year))
apply(crimeyear, allequal(year))
apply(crimeyear, allequal() year)
apply(crimeyear, allequal(), year)
crime_data$group <- 76
crime <- as.character(input$crime)
ifelse(year == "All Years",
year <- as.numeric(c(2004:2014)),
year <- as.numeric(input$year))
crime_data <- crime_data %>%
mutate(crimeyear = as.numeric(year(date)))
dt <- crime_data %>%
group_by(crimeyear, offense) %>%
subset(offense == crime)
year <- c(2013,2014)
crime <- "Rape"
apply(crimeyear, allequal(), year)
apply(dt$crimeyear, allequal(), year)
lapply(dt$crimeyear, allequal(x), year)
lapply(dt$crimeyear, all.equal(x), year)
lapply(dt$crimeyear, all.equal(), year)
lapply(dt$crimeyear, all.equal(year,x))
lapply(dt$crimeyear, all.equal(year)
)
lapply(dt$crimeyear, all.equal, year)
sapply(dt$crimeyear, all.equal, year)
sapply(dt$crimeyear[[2]], all.equal, year)
sapply(year, all.equal, dt$crimeyear)
sapply(year, all.equal, unique(dt$crimeyear))
unique(dt$crimeyear)
year
intersect(unique(dt$crimeyear), year)
crimeyear == year
dt$crimeyear == year
dt$crimeyear == (2013 & 2014)
dt$crimeyear == (2013 | 2014)
dt$crimeyear == 2013 | 2014
dt$crimeyear == 2013
dt$crimeyear == 2013 | dt$crimeyear == 2014
dt$crimeyear == 2014
exists(dt$crimeyear, year)
exists(dt$crimeyear, 2014)
dt$crimeyear %in% 2013
dt$crimeyear %in% c(2013,2014)
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear %in% year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,crimeyear !%in% year),binwidth=1,fill="gray25") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste(paste("Number of",crime),"s")) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
ggplot(dt, aes(crimeyear)) +
geom_histogram(data=subset(dt,crimeyear %in% year),binwidth=1,fill="red") +
geom_histogram(data=subset(dt,!(crimeyear %in% year)),binwidth=1,fill="gray25") +
coord_cartesian(xlim = c(min(crime_data$crimeyear)-1, max(crime_data$crimeyear)+2)) +
xlab("Year Reported") + ylab(paste(paste("Number of",crime),"s")) +
ggtitle(paste(paste("Number of Cases of",crime),"per Year")) +
scale_x_discrete(breaks=c(2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014))
shinyapps::setAccountInfo(name='miguelconner4',
token='09DA1DF510B2C9474E847055BE2D11C2',
secret='<SECRET>')
install.packages('devtools')
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='miguelconner4',
token='09DA1DF510B2C9474E847055BE2D11C2',
secret='<SECRET>')
shinyapps::setAccountInfo(name='miguelconner4',
token='09DA1DF510B2C9474E847055BE2D11C2',
secret='ME0mzXpiKJD338VeU834ocbRpej6sqR8OClzvS6X')
c(2004:2014)+0.5
require(grid.Extra)
require(gridExtra)
min(crime_data$crimeyear)
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(ggmap))
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(require(gridExtra))
# Covert to lat and long.
NAD.to.latlong <- function(coords){
proj <- "+proj=lcc +lat_1=44.33333333333334 +lat_2=46 +lat_0=43.66666666666666 +lon_0=-120.5 +x_0=2500000 +y_0=0 +ellps=GRS80 +units=ft +no_defs"
coords <-
as.data.frame(coords) %>%
SpatialPoints(proj4string=CRS(proj)) %>%
spTransform(CRS("+proj=longlat +ellps=WGS84")) %>%
.@coords %>%
as.data.frame() %>%
rename(long=X.Coordinate, lat=Y.Coordinate)
return(coords)
}
google.map <-
get_map(location = "Portland, OR", maptype = "roadmap", zoom = 10, color = "color")
# Import data. CSV files from all years have been merged into one file using Terminal.
crime_data <- read.csv("crime_data.csv", header = TRUE) %>% tbl_df()
# Clean up date data.
suppressWarnings(
crime_data <- crime_data %>% mutate(date = mdy(date))
)
# A certain number of the geocoordinates are missing.
# Remove these.  We have to be careful about the bias this may entail.  A more
# thorough analysis would see if there is a pattern in which data are missing.
suppressWarnings(
crime_data <- crime_data %>%
mutate(
X.Coordinate = as.numeric(as.character(X.Coordinate)),
Y.Coordinate = as.numeric(as.character(Y.Coordinate))
) %>%
filter(!is.na(X.Coordinate) & !is.na(Y.Coordinate)) %>%
filter(X.Coordinate != "" & Y.Coordinate != "")
)
lat.long <-
select(crime_data, X.Coordinate, Y.Coordinate) %>%
NAD.to.latlong()
crime_data <- bind_cols(crime_data, lat.long)
crime_data <- crime_data %>%
mutate(crimeyear = as.numeric(year(date)))
crime_data <- crime_data %>%
mutate(crimeyear = as.numeric(year(as.POSIXlt(date))))
crime_data$date
install.packages("BH")
download.file("http://www.openintro.org/stat/data/evals.RData", destfile = "evals.RData")
load("evals.RData")
plot(m_pick$residuals ~ evals$gender)
abline(h = 0, lty = 3)
m_pick <- lm(score ~ gender + language + age + cls_perc_eval + cls_credits +
bty_avg + pic_color, data = evals)
plot(m_pick$residuals ~ evals$gender)
abline(h = 0, lty = 3)
hist(evals$gender)
plot(m_pick$residuals ~ evals$age)
plot(m_pick$residuals ~ evals$language)
View(evals)
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(magritter))
suppressPackageStartupMessages(library(magrittr))
n <- 25
start.date <- "2015-04-01"
end.date <- "2015-04-30"
reed <- read.csv("reedcollege.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
portland <- read.csv("portland.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
setwd("~/Desktop/Math  241 (Case Studies - Statistical Analysis)/Math-241-Assignments/HW5")
n <- 25
start.date <- "2015-04-01"
end.date <- "2015-04-30"
reed <- read.csv("reedcollege.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
portland <- read.csv("portland.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
View(reed)
suppressPackageStartupMessages(library(wordcloud))
suppressPackageStartupMessages(library(tm))
?tolower
View(reed)
reed$V1 %<>% tolower() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
View(reed)
top.reed <- str_split(reed, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(stringr))
install.packages("stringr")
install.packages("stringr")
suppressPackageStartupMessages(library(stringr))
top.reed <- str_split(reed, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(wordcloud))
suppressPackageStartupMessages(library(tm))
suppressPackageStartupMessages(library(stringr))
# Define parameters.
n <- 25
start.date <- "2015-04-01"
end.date <- "2015-04-30"
# Import data.
reed <- read.csv("reedcollege.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
portland <- read.csv("portland.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
# Start by cleaning text. We'll leave numbers in there, since it could be interesting
# to see graduates from each class (i.e. '04, etc.).
reed$V1 %<>% tolower() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
top.reed <- str_split(reed, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
reed$V1 %<>% tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
reed <- read.csv("reedcollege.comments.csv", stringsAsFactors = FALSE, header=FALSE) %>%
tbl_df()
reed$V1 %<>% tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
top.reed <- str_split(reed, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
is.atomic(reed)
as.atomic(reed)
as.matrix(reed)
top.reed <- str_split(as.matrix(reed), pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
top.reed %>% names()
VectorSource(reed$V1) %>% Corpus()
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=TRUE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
n <- 100
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
top.reed %>% names()
VectorSource(reed$V1) %>% Corpus()
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
n <- 50
reed$V1 %<>% tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
top.reed %>% names()
VectorSource(reed$V1) %>% Corpus()
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
if (!requireNamespace('htmlwidgets') || packageVersion('htmlwidgets') <= '0.3.2')
devtools::install_github('ramnathv/htmlwidgets')
devtools::install_github('rstudio/DT')
library(DT)
DT::datatable(iris)
DT::datatable(iris)
devtools::install_github('rstudio/DT')
devtools::install_github('ramnathv/htmlwidgets')
devtools::install_github('rstudio/DT')
?datatable
devtools::install_github('rstudio/DT')
update.packages(ask = FALSE)
install.packages(
c("DT", "shiny")
type = "source",
repos = c("http://yihui.name/xran", "http://cran.rstudio.com")
)
update.packages(ask = FALSE)
install.packages(
c("DT", "shiny")
type = "source",
repos = c("http://yihui.name/xran", "http://cran.rstudio.com")
)
if (!requireNamespace('htmlwidgets') || packageVersion('htmlwidgets') <= '0.3.2')
devtools::install_github('ramnathv/htmlwidgets')
devtools::install_github('rstudio/DT')
update.packages(ask = FALSE)
install.packages(
c("DT", "shiny")
type = "source",
repos = c("http://yihui.name/xran", "http://cran.rstudio.com")
)
if (!requireNamespace('htmlwidgets') || packageVersion('htmlwidgets') <= '0.3.2')
devtools::install_github('ramnathv/htmlwidgets')
# install DT
if (!require("DT")) devtools::install_github("rstudio/DT")
sessionInfo()
?datatable
library(DT)
install.packages("htmlwidgets")
install.packages("htmlwidgets")
library(htmlwidgets)
library(DT)
install_github("rstudio/DT")
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(wordcloud))
suppressPackageStartupMessages(library(tm))
suppressPackageStartupMessages(library(stringr))
if (!requireNamespace('htmlwidgets') || packageVersion('htmlwidgets') <= '0.3.2')
devtools::install_github('ramnathv/htmlwidgets')
install_github("rstudio/DT")
library(DT)
if (!require("DT")) devtools::install_github("rstudio/DT")
sessionInfo()
library(DT)
d?atatable()
?datatable()
datatable(top.reed)
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n]
top.reed
top.reed[[1]]
top.reed[[2]]
names(top.reed)
df(names(top.reed), top.reed)
data.frame(names(top.reed), top.reed)
data.frame(top.reed)
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame()
datatable(top.reed)
n <- 20
reed$V1 %<>% tolower() %>%
removeNumbers() %>%
removePunctuation() %>%
removeWords(stopwords("english")) %>%
stemDocument() %>%
stripWhitespace()
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame()
datatable(top.reed)
VectorSource(reed$V1) %>% Corpus()
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "BuPu"))
VectorSource(reed$V1) %>% Corpus()
wordcloud(reed$V1, scale=c(5,0.5), max.words=n, random.order=FALSE,
rot.per=0.35, use.r.layout=FALSE, colors=brewer.pal(8, "Reds"))
colnames(top.reed) <- c("Word", "Counts")
colnames(top.reed)[1] <- Word
colnames(top.reed)[1] <- "Word""
colnames(top.reed)[1] <- "Word"
colnames(top.reed)
colnames(top.reed)[1]
colnames(top.reed)[1] <- "Word"
colnames(top.reed)
datatable(top.reed)
colnames(top.reed)[1] <- "Counts"
colnames(top.reed)[2]
colnames(top.reed)[0]
colnames(top.reed)[0] <- "Word"
datatable(top.reed)
colnames(top.reed)[0] <- "Word"
datatable(top.reed)
colnames(top.reed)[0] <- "Word"
View(top.reed)
colnames(top.reed$row.names) <- "Word"
colnames(top.reed$row.names)
top.reed$row.names
colnames(top.reed$row.name) <- "Word"
View(top.reed)
top.reed$row.names
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame()
top.reed$row.names
names(top.reed)
colnames(top.reed)[1] <- "Counts"
colnames(top.reed) <- c("Word", "Counts")
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame(seq(1:n),.)
View(top.reed)
names(top.reed)
top.reed <- str_split(reed$V1, pattern= " ") %>%
unlist() %>%
table() %>%
sort(decreasing=TRUE) %>%
.[1:n] %>%
data.frame()
top.reed <- cbind(rownames(top.reed), top.reed)
top.reed
rownames(top.reed) <- NULL
top.reed
colnames(top.reed) <- c("Rank","Word","Counts")
colnames(top.reed) <- c("Rank","Word","Counts")
colnames(top.reed) <- c("Word","Counts")
datatable(top.reed)
old.man <-
readLines("old_man_and_the_sea.txt", encoding="UTF-8") %>%
as.character()
VectorSource(reed$V1) %>% Corpus()
invisible(VectorSource(reed$V1) %>% Corpus())
