ggtitle("Predicting A Female Profile")
#Import and clean 'profiles' data.
profiles <- read.csv("profiles.csv", header=TRUE) %>% tbl_df()
# Split off the essays into a separate data.frame
essays <- select(profiles, contains("essay"))
profiles <- select(profiles, -contains("essay"))
# Define a binary outcome variable
# y_i = 1 if female
# y_i = 0 if male
profiles <- mutate(profiles, is.female = ifelse(sex=="f", 1, 0))
# Last Online
profiles$last_online <- str_sub(profiles$last_online, 1, 10) %>% as.Date()
ggplot(profiles, aes(height, fill = sex)) +
geom_histogram(binwidth = 1)
ggplot(profiles, aes(job, fill = sex)) +
geom_bar(position = "dodge") +
theme(axis.text.x=element_text(angle=45, hjust=1))
profiles %<>%
mutate("in.tech" = ifelse(profiles$job == "computer / hardware / software" |
profiles$job == "science / tech / engineering", 1, 0))
ggplot(profiles, aes(body_type, fill = sex)) +
geom_bar(position = "dodge") +
theme(axis.text.x=element_text(angle=45, hjust=1)) +
xlab("Body Type") +
ylab("Count")
profiles %<>% mutate("is.athletic" = ifelse(profiles$body_type=="athletic", 1, 0))
profiles %<>% mutate("is.curvy" = ifelse(profiles$body_type=="curvy", 1, 0))
# Split into halfs.
profilesa <- slice(profiles, 1:(nrow(profiles)/2))
profilesb <- slice(profiles, (nrow(profiles)/2 + 1):nrow(profiles))
# Train with first half.
testmodel <- glm(is.female ~ height + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
ggplot(profilesb, aes(jitter(is.female), predictions)) +
geom_point(size = 2) +
geom_abline(intercept = 0, size = 1) +
xlab("is.female") +
ylab("Prediction") +
ggtitle("Predicting A Female Profile")
profiles$username.len <- profiles$username %>% as.character %>% nchar()
library(stringr)
library(scales)
values <- group_by(profiles, sex, username.len) %>%
summarise(count=n()) %>%
mutate(perc=count/sum(count))
values
# Ask yourself.  Is there a difference in how males and females choose
# usernames?
ggplot(data=values, aes(x=as.factor(username.len), y=perc)) +
geom_bar(stat="identity") +
facet_wrap(~sex, nrow=1) +
scale_y_continuous(labels = percent) +
xlab("# of characters") + ylab("Proportion")
# Alternatively, use density estimates.  Who has the longer usernames?
ggplot(data=profiles, aes(x=username.len, fill=sex)) + geom_density(alpha=.3)
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
profilesa <- slice(profiles, 1:(nrow(profiles)/2))
profilesb <- slice(profiles, (nrow(profiles)/2 + 1):nrow(profiles))
# Train with first half.
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
ggplot(profilesb, aes(jitter(is.female), predictions)) +
geom_point(size = 2) +
geom_abline(intercept = 0, size = 1) +
xlab("is.female") +
ylab("Prediction") +
ggtitle("Predicting A Female Profile")
testmodel <- glm(is.female ~ height + factor(in.tech)  +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
ggplot(profilesb, aes(jitter(is.female), predictions)) +
geom_point(size = 2) +
geom_abline(intercept = 0, size = 1) +
xlab("is.female") +
ylab("Prediction") +
ggtitle("Predicting A Female Profile")
arrange(predictions ~ is.female, data = profilesb, mean = mean(predictions))
arrange(data = profilesb, mean = mean(predictions))
aggregate(is.female~predictions, data=profilesb, FUN=function(x) c(mean=mean(predictions)))
predictions
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(is.female ~ predictions, data=profilesb, FUN=function(x) c(mean=mean(predictions)))
View(profilesb)
aggregate(is.female ~ predictions, data=profilesb, c(mean=mean(predictions)))
aggregate(is.female ~ predictions, data=profilesb, FUN=function(x) c(mean=mean(x)))
aggregate(is.female ~ predictions, data=profilesb, FUN=function(predictions) c(mean=mean(predictions)))
aggregate(is.female ~ predictions, data=profilesb, mean=mean(predictions))
aggregate(is.female ~ predictions, data=profilesb, FUN=function(predictions), mean=mean(predictions))
aggregate(is.female ~ predictions, data=profilesb, FUN=function(predictions) mean=mean(predictions)))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech)  +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
ggplot(profilesb, aes(jitter(is.female), predictions)) +
geom_point(size = 2) +
geom_abline(intercept = 0, size = 1) +
xlab("is.female") +
ylab("Prediction") +
ggtitle("Predicting A Female Profile")
testmodel <- glm(is.female ~ factor(in.tech) + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len +
factor(is.athletic) , family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech) + username.len + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + username.len +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + username.len + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
profilesa <- slice(profiles, 1:(nrow(profiles)/2))
profilesb <- slice(profiles, (nrow(profiles)/2 + 1):nrow(profiles))
# Train with first half.
testmodel <- glm(is.female ~ height + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
testmodel <- glm(is.female ~ height + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Split into halfs.
profilesa <- slice(profiles, 1:(nrow(profiles)/2))
profilesb <- slice(profiles, (nrow(profiles)/2 + 1):nrow(profiles))
# Train with first half.
testmodel <- glm(is.female ~ height + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profilesa)
# Make predictions and convert to usable value with inverse logit function.
profilesb$predictions <- predict(testmodel, profilesb)
profilesb$predictions <- 1/(1+exp(-profilesb$predictions))
aggregate(predictions~is.female, data=profilesb, FUN=function(predictions) mean=mean(predictions))
ggplot(profilesb, aes(jitter(is.female), predictions)) +
geom_point(size = 2) +
geom_abline(intercept = 0, size = 1) +
xlab("is.female") +
ylab("Prediction") +
ggtitle("Predicting A Female Profile")
b
model <- glm(is.female ~ height + factor(in.tech) +
factor(is.athletic) + factor(is.curvy), family = binomial, data = profiles)
summary(model)
b <- coefficients(model)
b
qplot(fitted(model3)) + xlab("Fitted Probability of Being Female")
ggplot(data=profiles, aes(x=username.len, fill=sex)) + geom_density(alpha=.3)
#------------------
# Analysis:
#------------------
# -a) Means: Looking at the above histograms, the lengths for the men are higher
group_by(profiles, is.female) %>%
summarise(mean=mean(username.len), SE=sd(username.len)/n())
# -b) Regression, coefficients, and fitted values
model3 <- glm(is.female ~ username.len, data=profiles, family=binomial)
summary(model3)
# We apply the inverse logit FUNCTION to the regression equation: now we have a
# numerical input x
b3 <- coefficients(model3)
# Histogram of fitted p.hat's.  CRUCIAL:  compare the range of these fitted
# p.hats to the ones from the model that uses height.  What does this tell you
# about using username length as a predictor?
qplot(fitted(model3)) + xlab("Fitted Probability of Being Female")
-a) Means: Looking at the above histograms, the heights of the men are higher,
# but is the difference significant?  What is SE?  How does this help us tell if
# there is a significant difference?
group_by(profiles, is.female) %>% summarise(mean=mean(height), SE=sd(height)/n())
# -b) Regression, coefficients, and fitted values
model2 <- glm(is.female ~ height, data=profiles, family=binomial)
summary(model2)
# We apply the inverse logit FUNCTION to the regression equation: i.e. instead
# of a categorical predictor, we now we have a numerical input x.
b2 <- coefficients(model2)
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x
1/(1+exp(-linear.equation))
}
# Histogram of fitted p.hat's.  What is the range of the p.hats?  How does this
# compare to our original model0 p.hat?
qplot(fitted(model2)) + xlab("Fitted Probability of Being Female")
# -c) Plot.  Again, we add some jitter so we can better visualize the number of
# points involved for each height.
p2 <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point() + xlab("height") + ylab("is female")
p2
p2 + stat_function(fun = regression.line, args=list(b=b2), color="blue", size=2)
b <- coefficients(model)
b
b=b2
list(b=b2)
list(b=b4)
list(b=b3)
list(b[1],b[2])
b <- coefficients(model)
b
1/(1+exp(-b))
b
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x
1/(1+exp(-linear.equation))
}
model <- glm(is.female ~ height + factor(in.tech), family = binomial, data = profiles)
summary(model)
b <- coefficients(model)
b
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() + xlab("height") + ylab("is female")
p
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p
p + stat_function(fun = regression.line, args=list(b=b2), color="blue", size=2)
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x + b[3]*in.tech
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b=b2), color="blue", size=2)
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x + b[3]*in.tech
1/(1+exp(-linear.equation))
}
regression.line <- function(x, b){
linear.equation <- b[1] + b[2]*x + b[3]*factor(in.tech)
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b=b2), color="blue", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b=b2), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=(x,b,factor(in.tech)), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=c(x,b,factor(in.tech)), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=c(b,factor(in.tech)), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b,factor(in.tech)), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 1), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="blue", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="red", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="blue", size=2)
model <- glm(is.female ~ height + factor(in.tech) + factor(is.athletic) +
factor(is.curvy), family = binomial, data = profiles)
summary(model)
b <- coefficients(model)
b
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="red", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="blue", size=2)
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#F8766D", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00BFC4", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[4]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(is.curvy))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#F8766D", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00BFC4", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[5]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(is.curvy))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#F8766D", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00BFC4", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00BFC4", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(in.tech))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[5]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = factor(is.curvy))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female), col = sex)) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[5]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point() +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
b
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(col=is.curvy) +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(col=factor(is.curvy)) +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
xlab("height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[5]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
xlab("Height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
scale_colour_discrete("is.curvy") +
xlab("Height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(in.tech))) +
scale_colour_discrete("in.tech") +
xlab("Height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[3]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(in.tech))) +
scale_colour_discrete("in.tech") +
xlab("Height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
regression.line <- function(x, y, b){
linear.equation <- b[1] + b[2]*x + b[5]*y
1/(1+exp(-linear.equation))
}
p <- ggplot(data=profiles, aes(x=jitter(height), y=jitter(is.female))) +
geom_point(aes(col=factor(is.curvy))) +
scale_colour_discrete("is.curvy") +
xlab("Height") +
ylab("is female")
p + stat_function(fun = regression.line, args=list(b = b, 0), color="#f75f55", size=2) +
stat_function(fun = regression.line, args=list(b = b, 1), color="#00a6ab", size=2)
setwd("~/Desktop/Math 241 (Case Studies - Statistical Analysis)/Math-241-Assignments/HW2")
ggplot(profiles, aes(height, fill = sex)) +
xlab("Heights") +
ylab("Counts") +
geom_histogram(binwidth = 1)
setwd("~/")
setwd("~/Desktop/Math 241 (Case Studies - Statistical Analysis)/Math-241-Assignments/HW2")
